{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dac8aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for 5 seconds\n",
      "Text: City above clouds flowing\n",
      "Recording for 5 seconds\n",
      "Text: a man walking above water\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import speech_recognition as sr\n",
    "import requests\n",
    "from PIL import ImageTk, Image\n",
    "import io\n",
    "\n",
    "def recognize_speech():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Recording for 5 seconds\")\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        audio = r.listen(source, timeout=5)\n",
    "\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        print(f\"Text: {text}\")\n",
    "        query_huggingface_api(text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"I'm sorry, I didn't get that.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Failed to convert speech to text: {e}\")\n",
    "\n",
    "def query_huggingface_api(text):\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-2-1\"\n",
    "    headers = {\"Authorization\": \"Bearer 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\"}\n",
    "    def query(payload):\n",
    "        response = requests.post(API_URL, headers=headers, json=payload)\n",
    "        return response.content\n",
    "    image_bytes = query({\n",
    "    \"inputs\": text})\n",
    "    show_image(image_bytes)\n",
    "\n",
    "def show_image(image_bytes):\n",
    "    global image_label  # Specify the global scope for the image_label variable\n",
    "\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image = image.resize((500, 500))\n",
    "    photo = ImageTk.PhotoImage(image)\n",
    "    image_label.configure(image=photo)\n",
    "    image_label.image = photo\n",
    "\n",
    "# Create the Tkinter window\n",
    "window = tk.Tk()\n",
    "window.title(\"Speech Recognition\")\n",
    "window.geometry(\"400x200\")\n",
    "\n",
    "# Create the UI components\n",
    "label = tk.Label(window, text=\"Click the button and speak something:\")\n",
    "label.pack(pady=10)\n",
    "\n",
    "button = tk.Button(window, text=\"Start Recording\", command=recognize_speech)\n",
    "button.pack(pady=10)\n",
    "\n",
    "# Create a new window to display the image\n",
    "image_window = tk.Toplevel(window)\n",
    "image_window.title(\"Image Display\")\n",
    "image_window.geometry(\"550x550\")\n",
    "\n",
    "# A label to show the image\n",
    "image_label = tk.Label(image_window)\n",
    "image_label.pack()\n",
    "\n",
    "\n",
    "\n",
    "# Run the Tkinter event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93021b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
